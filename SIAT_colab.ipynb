{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2358eef",
   "metadata": {},
   "source": [
    "# SIAT: Social Interaction-Aware Transformer â€” Colab Notebook\n",
    "\n",
    "This notebook is a self-contained, Colab-ready version of the SIAT codebase. It includes all modules inline and runnable end-to-end: setup, preprocessing (ETH/UCY -> NPZ), dataset, model (GCN + Transformer), training, and evaluation with visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Install deps and configure paths (Colab-friendly)\n",
    "import sys, os, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print('Running in Colab:', IN_COLAB)\n",
    "\n",
    "# Optional: Mount Google Drive to persist data/checkpoints\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive', force_remount=False)\n",
    "        BASE_DIR = Path('/content/drive/MyDrive/SIAT')\n",
    "    except Exception:\n",
    "        BASE_DIR = Path('/content/SIAT')\n",
    "else:\n",
    "    BASE_DIR = Path.cwd()\n",
    "\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR = BASE_DIR / 'data_npz'\n",
    "CKPT_DIR = BASE_DIR / 'checkpoints'\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "DATASETS_DIR = BASE_DIR / 'datasets'\n",
    "for d in [DATA_DIR, CKPT_DIR, RESULTS_DIR, DATASETS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Install Python packages\n",
    "reqs = [\n",
    "    'numpy', 'pandas', 'torch', 'torchvision', 'torchaudio', 'matplotlib', 'tqdm'\n",
    "]\n",
    "for pkg in reqs:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except Exception:\n",
    "        print('Installing', pkg)\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "\n",
    "print('BASE_DIR =', BASE_DIR)\n",
    "print('DATA_DIR =', DATA_DIR)\n",
    "print('CKPT_DIR =', CKPT_DIR)\n",
    "print('RESULTS_DIR =', RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-download preprocessed data (data_npz) if missing\n",
    "import shutil, zipfile\n",
    "\n",
    "# Optional: set a ZIP archive URL containing data_npz (if you have one)\n",
    "DATA_ARCHIVE_URL = None  # e.g., 'https://example.com/SIAT_data_npz.zip'\n",
    "\n",
    "# GitHub raw fallback (public repo assumed)\n",
    "GITHUB_OWNER = 'VidushaSanidu'\n",
    "GITHUB_REPO = 'SIAT'\n",
    "GITHUB_BRANCH = 'main'\n",
    "GITHUB_FOLDER = 'data_npz'\n",
    "\n",
    "# Known NPZ filenames (from repository)\n",
    "NPZ_FILES = [\n",
    "    'eth_test_biwi_eth.npz',\n",
    "    'eth_train_biwi_hotel_train.npz',\n",
    "    'eth_train_crowds_zara01_train.npz',\n",
    "    'eth_train_crowds_zara02_train.npz',\n",
    "    'eth_train_crowds_zara03_train.npz',\n",
    "    'eth_train_students001_train.npz',\n",
    "    'eth_train_students003_train.npz',\n",
    "    'eth_train_uni_examples_train.npz',\n",
    "    'eth_val_biwi_hotel_val.npz',\n",
    "    'eth_val_crowds_zara01_val.npz',\n",
    "    'eth_val_crowds_zara02_val.npz',\n",
    "    'eth_val_crowds_zara03_val.npz',\n",
    "    'eth_val_students001_val.npz',\n",
    "    'eth_val_students003_val.npz',\n",
    "    'eth_val_uni_examples_val.npz',\n",
    "    'hotel_test_biwi_hotel.npz',\n",
    "    'hotel_train_biwi_eth_train.npz',\n",
    "    'hotel_train_crowds_zara01_train.npz',\n",
    "    'hotel_train_crowds_zara02_train.npz',\n",
    "    'hotel_train_crowds_zara03_train.npz',\n",
    "    'hotel_train_students001_train.npz',\n",
    "    'hotel_train_students003_train.npz',\n",
    "    'hotel_train_uni_examples_train.npz',\n",
    "    'hotel_val_biwi_eth_val.npz',\n",
    "    'hotel_val_crowds_zara01_val.npz',\n",
    "    'hotel_val_crowds_zara02_val.npz',\n",
    "    'hotel_val_crowds_zara03_val.npz',\n",
    "    'hotel_val_students001_val.npz',\n",
    "    'hotel_val_students003_val.npz',\n",
    "    'hotel_val_uni_examples_val.npz',\n",
    "    'raw_all_data_biwi_eth.npz',\n",
    "    'raw_all_data_biwi_hotel.npz',\n",
    "    'raw_all_data_crowds_zara01.npz',\n",
    "    'raw_all_data_crowds_zara02.npz',\n",
    "    'raw_all_data_crowds_zara03.npz',\n",
    "    'raw_all_data_students001.npz',\n",
    "    'raw_all_data_students003.npz',\n",
    "    'raw_all_data_uni_examples.npz',\n",
    "    'raw_train_biwi_eth_train.npz',\n",
    "    'raw_train_biwi_hotel_train.npz',\n",
    "    'raw_train_crowds_zara01_train.npz',\n",
    "    'raw_train_crowds_zara02_train.npz',\n",
    "    'raw_train_crowds_zara03_train.npz',\n",
    "    'raw_train_students001_train.npz',\n",
    "    'raw_train_students003_train.npz',\n",
    "    'raw_train_uni_examples_train.npz',\n",
    "    'raw_val_biwi_eth_val.npz',\n",
    "    'raw_val_biwi_hotel_val.npz',\n",
    "    'raw_val_crowds_zara01_val.npz',\n",
    "    'raw_val_crowds_zara02_val.npz',\n",
    "    'raw_val_crowds_zara03_val.npz',\n",
    "    'raw_val_students001_val.npz',\n",
    "    'raw_val_students003_val.npz',\n",
    "    'raw_val_uni_examples_val.npz',\n",
    "    'univ_test_students001.npz',\n",
    "    'univ_test_students003.npz',\n",
    "    'univ_train_biwi_eth_train.npz',\n",
    "    'univ_train_biwi_hotel_train.npz'\n",
    "]\n",
    "\n",
    "# Ensure requests is available\n",
    "try:\n",
    "    import requests\n",
    "except Exception:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'requests'])\n",
    "    import requests\n",
    "\n",
    "\n",
    "def download_file(url: str, dest: Path, chunk_size: int = 1 << 20) -> bool:\n",
    "    try:\n",
    "        with requests.get(url, stream=True, timeout=60) as r:\n",
    "            if r.status_code != 200:\n",
    "                return False\n",
    "            total = int(r.headers.get('content-length', 0) or 0)\n",
    "            with open(dest, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_zip_and_extract(url: str, out_dir: Path) -> bool:\n",
    "    tmp_zip = out_dir.parent / 'data_npz_tmp.zip'\n",
    "    print('Downloading zip:', url)\n",
    "    if not download_file(url, tmp_zip):\n",
    "        print('Zip download failed')\n",
    "        return False\n",
    "    try:\n",
    "        with zipfile.ZipFile(tmp_zip, 'r') as zf:\n",
    "            zf.extractall(out_dir)\n",
    "        print('Extracted to', out_dir)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('Zip extract failed:', e)\n",
    "        return False\n",
    "    finally:\n",
    "        try:\n",
    "            tmp_zip.unlink(missing_ok=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "def auto_download_data():\n",
    "    # Skip if data exists\n",
    "    if any(DATA_DIR.glob('*.npz')):\n",
    "        print('Data already present in', DATA_DIR)\n",
    "        return True\n",
    "\n",
    "    # Option 1: Zip archive URL\n",
    "    if DATA_ARCHIVE_URL:\n",
    "        ok = download_zip_and_extract(DATA_ARCHIVE_URL, DATA_DIR)\n",
    "        if ok and any(DATA_DIR.glob('*.npz')):\n",
    "            print('Data downloaded via ZIP archive.')\n",
    "            return True\n",
    "        print('ZIP archive route failed; falling back to GitHub raw files...')\n",
    "\n",
    "    # Option 2: Download each file from GitHub raw\n",
    "    base = f'https://raw.githubusercontent.com/{GITHUB_OWNER}/{GITHUB_REPO}/{GITHUB_BRANCH}/{GITHUB_FOLDER}'\n",
    "    success = 0\n",
    "    total = len(NPZ_FILES)\n",
    "    for name in NPZ_FILES:\n",
    "        url = f'{base}/{name}'\n",
    "        dest = DATA_DIR / name\n",
    "        if dest.exists():\n",
    "            success += 1\n",
    "            continue\n",
    "        ok = download_file(url, dest)\n",
    "        if ok:\n",
    "            success += 1\n",
    "        else:\n",
    "            # remove partial file if any\n",
    "            try:\n",
    "                if dest.exists():\n",
    "                    dest.unlink()\n",
    "            except Exception:\n",
    "                pass\n",
    "    print(f'Downloaded {success}/{total} files to', DATA_DIR)\n",
    "    if success == 0:\n",
    "        print('No files downloaded. You can:')\n",
    "        print('  - Set DATA_ARCHIVE_URL to a valid ZIP containing .npz files')\n",
    "        print('  - Upload your .txt files into', DATASETS_DIR, 'and run preprocessing')\n",
    "        print('  - Or upload .npz files directly into', DATA_DIR)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Trigger auto-download if data directory is empty\n",
    "_ = auto_download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    obs_len: int = 8\n",
    "    pred_len: int = 12\n",
    "    in_size: int = 2\n",
    "    embed_size: int = 64\n",
    "    enc_layers: int = 2\n",
    "    dec_layers: int = 1\n",
    "    nhead: int = 4\n",
    "    gcn_hidden: int = 64\n",
    "    gcn_layers: int = 2\n",
    "    dropout: float = 0.1\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    epochs: int = 20\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 1e-3\n",
    "    weight_decay: float = 0.0\n",
    "    grad_clip: Optional[float] = 1.0\n",
    "    device: str = 'auto'  # auto, cuda, mps, cpu\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    data_dir: str = str(DATA_DIR)\n",
    "    obs_len: int = 8\n",
    "    pred_len: int = 12\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    model: ModelConfig = field(default_factory=ModelConfig)\n",
    "    training: TrainingConfig = field(default_factory=TrainingConfig)\n",
    "    data: DataConfig = field(default_factory=DataConfig)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.model.obs_len = self.data.obs_len\n",
    "        self.model.pred_len = self.data.pred_len\n",
    "\n",
    "CFG = Config()\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and collate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "author_note = 'Target agent is at index 0 in each window.'\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, npz_files: list, obs_len: int = 8, pred_len: int = 12, transform=None):\n",
    "        self.samples = []\n",
    "        self.obs_len = obs_len\n",
    "        self.pred_len = pred_len\n",
    "        self.transform = transform\n",
    "        for f in npz_files:\n",
    "            data = np.load(f, allow_pickle=True)\n",
    "            if 'observations' in data and 'futures' in data and 'windows' in data:\n",
    "                observations = data['observations']\n",
    "                futures = data['futures']\n",
    "                windows = data['windows']\n",
    "                for i in range(len(observations)):\n",
    "                    obs = observations[i].astype(np.float32)\n",
    "                    fut = futures[i].astype(np.float32)\n",
    "                    window = windows[i].astype(np.float32)\n",
    "                    self.samples.append((obs, fut, window))\n",
    "            elif 'trajectories' in data:\n",
    "                trajs = data['trajectories']  # (N, T, 2)\n",
    "                N, T, _ = trajs.shape\n",
    "                for i in range(N):\n",
    "                    for start in range(0, T - (obs_len + pred_len) + 1):\n",
    "                        obs = trajs[i, start:start + obs_len]\n",
    "                        fut = trajs[i, start + obs_len:start + obs_len + pred_len]\n",
    "                        window = trajs[:, start:start + obs_len + pred_len]\n",
    "                        reordered_window = np.zeros_like(window)\n",
    "                        reordered_window[0] = window[i]\n",
    "                        other_idx = 1\n",
    "                        for j in range(N):\n",
    "                            if j != i:\n",
    "                                reordered_window[other_idx] = window[j]\n",
    "                                other_idx += 1\n",
    "                        self.samples.append((obs.astype(np.float32), fut.astype(np.float32), reordered_window.astype(np.float32)))\n",
    "            else:\n",
    "                raise ValueError(f'Unsupported .npz format in {f}.')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        obs, fut, window = self.samples[idx]\n",
    "        if self.transform:\n",
    "            obs, fut, window = self.transform(obs, fut, window)\n",
    "        return {\n",
    "            'obs': torch.from_numpy(obs),\n",
    "            'fut': torch.from_numpy(fut),\n",
    "            'window': torch.from_numpy(window)\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    obs_batch = torch.stack([item['obs'] for item in batch])\n",
    "    fut_batch = torch.stack([item['fut'] for item in batch])\n",
    "    max_agents = max(item['window'].size(0) for item in batch)\n",
    "    batch_size = len(batch)\n",
    "    seq_len = batch[0]['window'].size(1)\n",
    "    window_batch = torch.zeros(batch_size, max_agents, seq_len, 2)\n",
    "    agent_masks = torch.zeros(batch_size, max_agents, dtype=torch.bool)\n",
    "    for i, item in enumerate(batch):\n",
    "        n_agents = item['window'].size(0)\n",
    "        window_batch[i, :n_agents] = item['window']\n",
    "        agent_masks[i, :n_agents] = True\n",
    "    return {'obs': obs_batch, 'fut': fut_batch, 'window': window_batch, 'agent_mask': agent_masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30aca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: GCN layer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats: int, out_feats: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats, bias=bias)\n",
    "    def forward(self, X: torch.Tensor, A_norm: torch.Tensor) -> torch.Tensor:\n",
    "        H = torch.bmm(A_norm, X)\n",
    "        H = self.linear(H)\n",
    "        return F.relu(H)\n",
    "\n",
    "# Model: SIAT\n",
    "class SIAT(nn.Module):\n",
    "    def __init__(self, obs_len=8, pred_len=12, in_size=2, embed_size=64, enc_layers=2, dec_layers=1,\n",
    "                 nhead=4, gcn_hidden=64, gcn_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.obs_len = obs_len\n",
    "        self.pred_len = pred_len\n",
    "        self.in_size = in_size\n",
    "        self.embed_size = embed_size\n",
    "        seq_len = obs_len + pred_len\n",
    "        self.flatten_dim = seq_len * in_size\n",
    "        self.embedding = nn.Linear(self.flatten_dim, embed_size)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=nhead,\n",
    "                                                   dim_feedforward=embed_size*2, dropout=dropout, activation='relu')\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=enc_layers)\n",
    "        gcn_modules = []\n",
    "        gcn_in = embed_size\n",
    "        for _ in range(gcn_layers):\n",
    "            gcn_modules.append(GCNLayer(gcn_in, gcn_hidden))\n",
    "            gcn_in = gcn_hidden\n",
    "        self.gcn = nn.ModuleList(gcn_modules)\n",
    "        self.fuse_trans = nn.Linear(embed_size, embed_size)\n",
    "        self.fuse_gcn = nn.Linear(gcn_hidden, embed_size)\n",
    "        self.lambda1 = nn.Parameter(torch.tensor(0.5))\n",
    "        self.lambda2 = nn.Parameter(torch.tensor(0.5))\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_size, nhead=nhead,\n",
    "                                                   dim_feedforward=embed_size*2, dropout=dropout, activation='relu')\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=dec_layers)\n",
    "        self.reg_head = nn.Linear(embed_size, pred_len*2)\n",
    "        self._reset_parameters()\n",
    "    def _reset_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    def compute_adjacency(self, positions: torch.Tensor, sigma: float = 1.5, eps: float = 1e-6) -> torch.Tensor:\n",
    "        B, N, _ = positions.shape\n",
    "        pos_expand1 = positions.unsqueeze(2)\n",
    "        pos_expand2 = positions.unsqueeze(1)\n",
    "        diff = pos_expand1 - pos_expand2\n",
    "        dist2 = (diff**2).sum(-1)\n",
    "        A = torch.exp(-dist2 / (sigma**2 + eps))\n",
    "        deg = A.sum(-1)\n",
    "        deg_inv_sqrt = (deg + eps).pow(-0.5)\n",
    "        D_inv_sqrt = deg_inv_sqrt.unsqueeze(-1) * deg_inv_sqrt.unsqueeze(-2)\n",
    "        A_norm = A * D_inv_sqrt\n",
    "        return A_norm\n",
    "    def forward(self, obs: torch.Tensor, full_window: torch.Tensor, agent_mask: torch.Tensor | None = None) -> torch.Tensor:\n",
    "        B = obs.size(0)\n",
    "        N = full_window.size(1)\n",
    "        agent_flat = full_window.view(B, N, -1)\n",
    "        agent_emb = self.embedding(agent_flat)\n",
    "        if agent_mask is not None:\n",
    "            agent_emb = agent_emb * agent_mask.unsqueeze(-1).float()\n",
    "        agent_emb_t = agent_emb.permute(1, 0, 2)\n",
    "        src_key_padding_mask = (~agent_mask) if agent_mask is not None else None\n",
    "        trans_enc_out = self.transformer_encoder(agent_emb_t, src_key_padding_mask=src_key_padding_mask)\n",
    "        trans_enc_out = trans_enc_out.permute(1, 0, 2)\n",
    "        last_pos = full_window[:, :, self.obs_len - 1, :]\n",
    "        A_norm = self.compute_adjacency(last_pos)\n",
    "        if agent_mask is not None:\n",
    "            mask_matrix = agent_mask.unsqueeze(-1) & agent_mask.unsqueeze(-2)\n",
    "            A_norm = A_norm * mask_matrix.float()\n",
    "        H = agent_emb\n",
    "        for layer in self.gcn:\n",
    "            H = layer(H, A_norm)\n",
    "        H_trans_proj = self.fuse_trans(trans_enc_out)\n",
    "        H_gcn_proj = self.fuse_gcn(H)\n",
    "        H_fused = self.lambda1 * H_trans_proj + self.lambda2 * H_gcn_proj\n",
    "        target_feat = H_fused[:, 0, :].unsqueeze(0)\n",
    "        query = target_feat.repeat(self.pred_len, 1, 1)\n",
    "        memory = H_fused.permute(1, 0, 2)\n",
    "        memory_key_padding_mask = (~agent_mask) if agent_mask is not None else None\n",
    "        dec_out = self.transformer_decoder(tgt=query, memory=memory, memory_key_padding_mask=memory_key_padding_mask)\n",
    "        dec_out_mean = dec_out.permute(1, 0, 2).mean(dim=1)\n",
    "        reg = self.reg_head(dec_out_mean)\n",
    "        pred = reg.view(B, self.pred_len, 2)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics and training utils\n",
    "from typing import Tuple\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ade_fde(pred: torch.Tensor, gt: torch.Tensor) -> Tuple[float, float]:\n",
    "    err = torch.norm(pred - gt, dim=-1)\n",
    "    ade = err.mean().item()\n",
    "    fde = err[:, -1].mean().item()\n",
    "    return ade, fde\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, loader: DataLoader, device: torch.device, clip: float | None = 1.0) -> float:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(loader, desc='Training', leave=False)\n",
    "    for batch in pbar:\n",
    "        obs = batch['obs'].to(device)\n",
    "        fut = batch['fut'].to(device)\n",
    "        window = batch['window'].to(device)\n",
    "        agent_mask = batch['agent_mask'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(obs, window, agent_mask)\n",
    "        loss = F.mse_loss(pred, fut)\n",
    "        loss.backward()\n",
    "        if clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        bl = loss.item()\n",
    "        total_loss += bl * obs.size(0)\n",
    "        pbar.set_postfix({'loss': f'{bl:.6f}'})\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader: DataLoader, device: torch.device) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_ade = 0.0\n",
    "    total_fde = 0.0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Evaluating', leave=False)\n",
    "        for batch in pbar:\n",
    "            obs = batch['obs'].to(device)\n",
    "            fut = batch['fut'].to(device)\n",
    "            window = batch['window'].to(device)\n",
    "            agent_mask = batch['agent_mask'].to(device)\n",
    "            pred = model(obs, window, agent_mask)\n",
    "            ade, fde = ade_fde(pred, fut)\n",
    "            total_ade += ade * obs.size(0)\n",
    "            total_fde += fde * obs.size(0)\n",
    "            pbar.set_postfix({'ADE': f'{ade:.4f}', 'FDE': f'{fde:.4f}'})\n",
    "    n = len(loader.dataset)\n",
    "    return total_ade / n, total_fde / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: ETH/UCY -> NPZ\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_eth_ucy_file(file_path: str | Path):\n",
    "    data = pd.read_csv(file_path, sep='\\t', header=None, names=['frame', 'ped_id', 'x', 'y'])\n",
    "    trajectories = {}\n",
    "    for ped_id, group in data.groupby('ped_id'):\n",
    "        group_sorted = group.sort_values('frame')\n",
    "        coords = group_sorted[['x', 'y']].values\n",
    "        trajectories[int(ped_id)] = coords.astype(np.float32)\n",
    "    return trajectories\n",
    "\n",
    "\n",
    "def create_sliding_windows(trajectories, obs_len=8, pred_len=12, min_agents=2):\n",
    "    samples = []\n",
    "    total_len = obs_len + pred_len\n",
    "    if len(trajectories) < min_agents:\n",
    "        return samples\n",
    "    ped_ids = list(trajectories.keys())\n",
    "    ped_trajs = [trajectories[pid] for pid in ped_ids]\n",
    "    valid_trajs = [(pid, traj) for pid, traj in zip(ped_ids, ped_trajs) if len(traj) >= total_len]\n",
    "    if len(valid_trajs) < min_agents:\n",
    "        return samples\n",
    "    max_frames = max(len(traj) for _, traj in valid_trajs)\n",
    "    for start_frame in range(max_frames - total_len + 1):\n",
    "        end_frame = start_frame + total_len\n",
    "        window_data = []\n",
    "        for pid, traj in valid_trajs:\n",
    "            if len(traj) >= end_frame:\n",
    "                window_data.append(traj[start_frame:end_frame])\n",
    "        if len(window_data) < min_agents:\n",
    "            continue\n",
    "        window_array = np.array(window_data)\n",
    "        for target_idx in range(len(window_data)):\n",
    "            target_obs = window_array[target_idx, :obs_len]\n",
    "            target_fut = window_array[target_idx, obs_len:]\n",
    "            reordered_window = np.zeros_like(window_array)\n",
    "            reordered_window[0] = window_array[target_idx]\n",
    "            other_idx = 1\n",
    "            for i in range(len(window_data)):\n",
    "                if i != target_idx:\n",
    "                    reordered_window[other_idx] = window_array[i]\n",
    "                    other_idx += 1\n",
    "            final_window = reordered_window[:len(window_data)]\n",
    "            samples.append((target_obs, target_fut, final_window))\n",
    "    return samples\n",
    "\n",
    "\n",
    "def preprocess_scene(input_file: str | Path, output_file: str | Path, obs_len=8, pred_len=12):\n",
    "    trajectories = load_eth_ucy_file(input_file)\n",
    "    if not trajectories:\n",
    "        return False\n",
    "    samples = create_sliding_windows(trajectories, obs_len, pred_len)\n",
    "    if len(samples) == 0:\n",
    "        return False\n",
    "    obs_list, fut_list, window_list = [], [], []\n",
    "    for obs, fut, window in samples:\n",
    "        obs_list.append(obs)\n",
    "        fut_list.append(fut)\n",
    "        window_list.append(window)\n",
    "    output_file = Path(output_file)\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(output_file, observations=np.array(obs_list), futures=np.array(fut_list), windows=np.array(window_list, dtype=object))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/Evaluation runners\n",
    "import glob, time\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "def setup_device(arg='auto'):\n",
    "    if arg == 'auto':\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device('cuda')\n",
    "        try:\n",
    "            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "                return torch.device('mps')\n",
    "        except Exception:\n",
    "            pass\n",
    "        return torch.device('cpu')\n",
    "    return torch.device(arg)\n",
    "\n",
    "\n",
    "def create_datasets(data_dir: Path, obs_len: int, pred_len: int, batch_size: int, num_workers: int = 2):\n",
    "    npz_files = glob.glob(str(data_dir / '*.npz'))\n",
    "    if len(npz_files) == 0:\n",
    "        raise RuntimeError(f'No .npz files found in {data_dir}. Place data or run preprocessing.')\n",
    "    full_dataset = TrajectoryDataset(npz_files, obs_len=obs_len, pred_len=pred_len)\n",
    "    total = len(full_dataset)\n",
    "    train_size = max(1, int(0.8 * total))\n",
    "    val_size = total - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "    use_pin = torch.cuda.is_available()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn, pin_memory=use_pin)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn, pin_memory=use_pin)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def train_model(cfg: Config):\n",
    "    device = setup_device(cfg.training.device)\n",
    "    print('Device:', device)\n",
    "    train_loader, val_loader = create_datasets(Path(cfg.data.data_dir), cfg.model.obs_len, cfg.model.pred_len, cfg.training.batch_size)\n",
    "    model = SIAT(obs_len=cfg.model.obs_len, pred_len=cfg.model.pred_len, embed_size=cfg.model.embed_size).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.training.learning_rate, weight_decay=cfg.training.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "    best_ade = float('inf')\n",
    "    best_path = None\n",
    "    for epoch in range(1, cfg.training.epochs + 1):\n",
    "        t0 = time.time()\n",
    "        train_loss = train_one_epoch(model, optimizer, train_loader, device, cfg.training.grad_clip)\n",
    "        val_ade, val_fde = evaluate(model, val_loader, device)\n",
    "        scheduler.step(val_ade)\n",
    "        dt = time.time() - t0\n",
    "        print(f'Epoch {epoch:03d}/{cfg.training.epochs} | Loss {train_loss:.6f} | ADE {val_ade:.4f} | FDE {val_fde:.4f} | time {dt:.1f}s')\n",
    "        if val_ade < best_ade:\n",
    "            best_ade = val_ade\n",
    "            best_path = CKPT_DIR / 'best_model.pth'\n",
    "            torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'best_ade': best_ade, 'obs_len': cfg.model.obs_len, 'pred_len': cfg.model.pred_len, 'embed_size': cfg.model.embed_size}, best_path)\n",
    "            print('Saved best checkpoint:', best_path)\n",
    "    return best_path\n",
    "\n",
    "\n",
    "def evaluate_model(checkpoint_path: Path, data_dir: Path, batch_size: int = 32, device_arg: str = 'auto', visualize: bool = True, num_samples: int = 10):\n",
    "    device = setup_device(device_arg)\n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "    obs_len = int(ckpt.get('obs_len', 8))\n",
    "    pred_len = int(ckpt.get('pred_len', 12))\n",
    "    embed_size = int(ckpt.get('embed_size', 64))\n",
    "    model = SIAT(obs_len=obs_len, pred_len=pred_len, embed_size=embed_size).to(device)\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    model.eval()\n",
    "    dataset = TrajectoryDataset(glob.glob(str(data_dir / '*.npz')), obs_len=obs_len, pred_len=pred_len)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
    "    all_pred, all_gt, all_obs = [], [], []\n",
    "    total_ade = 0.0\n",
    "    total_fde = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            obs = batch['obs'].to(device)\n",
    "            fut = batch['fut'].to(device)\n",
    "            window = batch['window'].to(device)\n",
    "            agent_mask = batch['agent_mask'].to(device)\n",
    "            pred = model(obs, window, agent_mask)\n",
    "            ade, fde = ade_fde(pred, fut)\n",
    "            b = obs.size(0)\n",
    "            total_ade += ade * b\n",
    "            total_fde += fde * b\n",
    "            n += b\n",
    "            all_pred.append(pred.cpu().numpy())\n",
    "            all_gt.append(fut.cpu().numpy())\n",
    "            all_obs.append(obs.cpu().numpy())\n",
    "    final_ade = total_ade / max(1, n)\n",
    "    final_fde = total_fde / max(1, n)\n",
    "    print('Evaluation: ADE=', final_ade, 'FDE=', final_fde, 'Samples=', n)\n",
    "    preds = np.concatenate(all_pred, axis=0) if all_pred else np.empty((0, pred_len, 2))\n",
    "    gts = np.concatenate(all_gt, axis=0) if all_gt else np.empty((0, pred_len, 2))\n",
    "    obss = np.concatenate(all_obs, axis=0) if all_obs else np.empty((0, obs_len, 2))\n",
    "    if visualize and len(preds) > 0:\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "            idxs = np.random.choice(len(preds), min(num_samples, len(preds)), replace=False)\n",
    "            for i, idx in enumerate(idxs):\n",
    "                plt.figure(figsize=(7,6))\n",
    "                obs_i, pred_i, gt_i = obss[idx], preds[idx], gts[idx]\n",
    "                plt.plot(obs_i[:,0], obs_i[:,1], 'b-o', label='Observed')\n",
    "                plt.plot(pred_i[:,0], pred_i[:,1], 'r-s', label='Predicted')\n",
    "                plt.plot(gt_i[:,0], gt_i[:,1], 'g-^', label='Ground Truth')\n",
    "                plt.legend(); plt.grid(True, alpha=0.3); plt.axis('equal')\n",
    "                plt.title(f'Trajectory sample {idx}')\n",
    "                out = RESULTS_DIR / f'trajectory_{idx}.png'\n",
    "                plt.savefig(out, dpi=150, bbox_inches='tight'); plt.close()\n",
    "            print('Saved visualizations to', RESULTS_DIR)\n",
    "        except Exception as e:\n",
    "            print('Visualization skipped:', e)\n",
    "    return {'ade': float(final_ade), 'fde': float(final_fde), 'num_samples': int(n)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Preprocess all ETH/UCY .txt under DATASETS_DIR\n",
    "from typing import List\n",
    "\n",
    "def preprocess_all(input_dir: Path = DATASETS_DIR, output_dir: Path = DATA_DIR, obs_len=8, pred_len=12) -> int:\n",
    "    txt_files: List[Path] = [p for p in input_dir.rglob('*.txt')]\n",
    "    print('Found', len(txt_files), '.txt files')\n",
    "    ok = 0\n",
    "    for p in txt_files:\n",
    "        rel = p.relative_to(input_dir).as_posix().replace('/', '_')\n",
    "        out = output_dir / (Path(rel).stem + '.npz')\n",
    "        try:\n",
    "            if preprocess_scene(p, out, obs_len, pred_len):\n",
    "                ok += 1\n",
    "        except Exception as e:\n",
    "            print('Failed:', p, e)\n",
    "    print('Preprocessed OK:', ok)\n",
    "    return ok\n",
    "\n",
    "# If no data present, create dummy sample for quick run\n",
    "if len(list(DATA_DIR.glob('*.npz'))) == 0:\n",
    "    print('No .npz found, creating dummy_data.npz for a smoke test...')\n",
    "    N = 5; T = CFG.model.obs_len + CFG.model.pred_len\n",
    "    trajs = np.cumsum(np.random.randn(N, T, 2).astype(np.float32)*0.2, axis=1)\n",
    "    np.savez(DATA_DIR / 'dummy_data.npz', trajectories=trajs)\n",
    "    print('Dummy data saved to', DATA_DIR / 'dummy_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfab8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (set epochs higher on Colab GPU)\n",
    "CFG.training.epochs = 3  # Increase to 30+ for real training\n",
    "best_ckpt = train_model(CFG)\n",
    "best_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c73669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best checkpoint\n",
    "if best_ckpt is not None:\n",
    "    results = evaluate_model(best_ckpt, DATA_DIR, batch_size=32, device_arg=CFG.training.device, visualize=True, num_samples=6)\n",
    "    results\n",
    "else:\n",
    "    print('No checkpoint to evaluate.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
